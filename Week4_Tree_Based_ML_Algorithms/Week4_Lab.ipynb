{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics\n",
    "* Classification Accuracy\n",
    "* Logarithmic Loss\n",
    "* Area Under ROC Curve\n",
    "* Confusion Matrix\n",
    "* Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Classification Accurayc = `# of correct predictions / all predictions made`\n",
    "* More suitable when there are an equal number of observations in each class, and when all predictions and prediction errors are equally important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.770 (0.048)\n"
     ]
    }
   ],
   "source": [
    "# cross validation classification accuracy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = data.values[:,0:8]\n",
    "Y = data.values[:,8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state =7)\n",
    "model = LogisticRegression()\n",
    "scoring = \"accuracy\"\n",
    "\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = scoring)\n",
    "print(\"Accuracy:  %.3f (%.3f)\" % (results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic Loss (Logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probability between 0 and 1 is a measure of confidence for a prediction by an algorithm. \n",
    "* Smaller logloss = better performance. \n",
    "* 0 = perfect score\n",
    "\n",
    "* Smaller logloss is better with 0 representing a perfect logloss. As mentioned above, the measure is inverted to be ascending when using the cross_val_score() function. The actual logloss is simply the positive version of the number.SK-Learn's unified scoring API always maximises the score, so scores which need to be minimised are negated (made negative) in order for the unified scoring API to work correctly. The score that is returned is therefore negated when it is a score that should be minimised and left positive if it is a score that should be maximised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  -0.493 (0.047)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = data.values[:,0:8]\n",
    "Y = data.values[:,8]\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state =7)\n",
    "model = LogisticRegression()\n",
    "scoring = \"neg_log_loss\"\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = scoring)\n",
    "print(\"Accuracy:  %.3f (%.3f)\" % (results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under ROC Curve (AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Measures performance for binary classification problems\n",
    "* Represents a model's ability to discriminate between positive and negative classes\n",
    "* An area of 1 represents a model that made all predictions perfectly\n",
    "* An area of 0.5 represents a model that is as good as random\n",
    "* **Sensitivity** is the true positive rate, also known as **recall**. It is the number of instances from positive class that are actualy predicted correctly. True Positive Rate = True Positive / (True Positive + False Negative)\n",
    "* **Specificity** is the true negative rate. It is the number of instances from the negative class that are actually predicted correctly. False Positive Rate = False Postivie / (False Positive + True Negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve demonstrates:\n",
    "* It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n",
    "* The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n",
    "* The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.\n",
    "* The slope of the tangent line at a cutpoint gives the likelihood ratio (LR) for that value of the test.\n",
    "* The area under the curve = measure of test accuracy.\n",
    "* An area of 1 represents a perfect test; an area of .5 represents a worthless test. A rough guide for classifying the accuracy of a diagnostic test is the traditional academic point system:\n",
    "\n",
    "    + 1) .90-1 = excellent (A)\n",
    "\n",
    "    + 2) .80-.90 = good (B)\n",
    "\n",
    "    + 3) .70-.80 = fair (C)\n",
    "\n",
    "    + 4) .60-.70 = poor (D)\n",
    "\n",
    "    + 5) .50-.60 = fail (F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.808\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = data.values[:,0:8]\n",
    "Y = data.values[:,8]\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(X, Y, test_size=0.1, random_state=2)\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state =7)\n",
    "model = LogisticRegression()\n",
    "model.fit(trainX,trainy)\n",
    "probs = model.predict_proba(testX)\n",
    "# keep the probabilities for the positive outcome only\n",
    "probs = probs[:,1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(testy,probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(testy, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "scoring = \"roc_auc\"\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = scoring)\n",
    "print(\"Accuracy:  %.3f (%.3f)\" % (results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot a ROC curve for a model in Python using the `ùëüùëúùëê_ùëêùë¢ùëüùë£ùëí()` scikit-learn function. The function takes both the true outcomes (0,1) from the test set and the predicted probabilities for the 1 class. The function returns the false positive rates for each threshold, true positive rates for each threshold and thresholds. The AUC for the ROC can be calculated using the `ùëüùëúùëê_ùëéùë¢ùëê_ùë†ùëêùëúùëüùëí()` function. Like the `ùëüùëúùëê_ùëêùë¢ùëüùë£ùëí()` function, the AUC function takes both the true outcomes (0,1) from the test set and the predicted probabilities for the 1 class. It returns the AUC score between 0.0 and 1.0 for no skill and perfect skill respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "* Useful to show accuracy of a model with two or more classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = data.values[:,0:8]\n",
    "Y = data.values[:,8]\n",
    "\n",
    "test_size=0.33\n",
    "seed = 7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression() \n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "matrix = confusion_matrix(Y_test, predicted) \n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report \n",
    "`classification_report()` function in scikit-learn gives precision, recall, F1-score and support for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.87      0.82       162\n",
      "        1.0       0.71      0.55      0.62        92\n",
      "\n",
      "avg / total       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = data.values[:,0:8]\n",
    "Y = data.values[:,8]\n",
    "\n",
    "test_size=0.33\n",
    "seed = 7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression() \n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortlisting Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression\n",
    "* k-Nearest Neighbors\n",
    "* Classification and Regression Trees (CART)\n",
    "* Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** `LogisticRegression` \n",
    "\n",
    "Logistic regression assumes a **Gaussian distribution** (which requires normalisation) for the numeric input variables and can model binary classification problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.87      0.82       162\n",
      "        1.0       0.71      0.55      0.62        92\n",
      "\n",
      "avg / total       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = data.values[:,0:8]\n",
    "Y = data.values[:,8]\n",
    "\n",
    "test_size=0.33\n",
    "seed = 7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-Nearest Neighbors (KNN)** `KNeighborsClassifier`\n",
    "\n",
    "KNN uses a distance metric to find the k most similar instances in the training data for a new instance and takes the mean outcome of the neighbors as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265550239234451\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = data.values[:,0:8]\n",
    "Y = data.values[:,8]\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state=7)\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) `SVC`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM seek a line that best separates two classes. Those data instances that are closest to the line that best separates the classes are called support vectors and influence where the line is placed. SVM has been extended to support multiple classes. Of particular importance is the use of different kernel functions via the kernel parameter. A powerful Radial Basis Function is used by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6510252904989747\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = data.values[:,0:8]\n",
    "Y = data.values[:,8]\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state=7)\n",
    "model = SVC()\n",
    "\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification and Regression Trees (CART)  `DecisionTreeClassifier`\n",
    "\n",
    "CART constructs a binary tree from the training data. Split points are chosen greedily by evaluating each attribute and each value of each attribute in the training data in order to minimize a cost function (like the Gini index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
